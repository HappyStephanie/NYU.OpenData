{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c42d36c",
   "metadata": {},
   "source": [
    "#### It's said to use the cleaned data as training data and last week's data as testing data. However, last week we use the cleaned data for most of the time. I think it would be strange to use the cleaned data as both the training and testing data, therefore, I use the original data (also used in last week; in question 1) as the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "757b9db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load data \n",
    "ori = pd.read_csv(\"data/nyc_crashes_202301.csv\")\n",
    "clean = pd.read_csv(\"data/nyc_crashes_202301_cleaned.csv\")\n",
    "\n",
    "# Create new variable injury.\n",
    "clean['injury'] = clean['NUMBER OF PERSONS INJURED'].\\\n",
    "    apply(lambda x: 1 if x >= 1 else 0)\n",
    "ori['injury'] = ori['NUMBER OF PERSONS INJURED'].\\\n",
    "    apply(lambda x: 1 if x >= 1 else 0)\n",
    "\n",
    "# Construct a hour variable with integer values from 0 to 23\n",
    "clean['hour'] = pd.to_datetime(clean['CRASH TIME']).dt.hour\n",
    "ori['hour'] = pd.to_datetime(ori['CRASH TIME']).dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8a7f83f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7244, 3)\n",
      "(7189, 3)\n"
     ]
    }
   ],
   "source": [
    "# \"clean\" as training data and \"ori\" as testing data\n",
    "X_train = clean[['hour', 'CRASH DATE', 'BOROUGH']].values\n",
    "y_train = clean['injury'].values\n",
    "X_test = ori[['hour', 'CRASH DATE', 'BOROUGH']].values\n",
    "y_test = ori['injury'].values\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "067d9f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# encode catigorical variables \n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "X_test_encoded = encoder.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "df5afe79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fit SVM\n",
    "svm = SVC()\n",
    "svm.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Fit logistic regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "41c9bb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'C': 1, 'gamma': 1, 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "# define the hyperparameter space to search over for svm\n",
    "param_grid = {'C': [0.1, 1, 10],\n",
    "              'gamma': [0.01, 0.1, 1, 'scale', 'auto'],\n",
    "              'kernel': ['linear', 'rbf', 'sigmoid']}\n",
    "\n",
    "# perform cross-validation with GridSearchCV\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train_encoded, y_train)\n",
    "\n",
    "# print the best hyperparameters found\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bcad1cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=1, kernel=&#x27;sigmoid&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=1, kernel=&#x27;sigmoid&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, gamma=1, kernel='sigmoid')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit SVM using the Best hyperparameters \n",
    "svm2 = SVC(C = 1, gamma = 1, kernel = 'sigmoid')\n",
    "svm2.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fba56da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# define the hyperparameter grid for logistic regression\n",
    "param_grid_r = {\n",
    "    'C': [0.01, 0.1, 1],  # regularization parameter\n",
    "    'penalty': ['l1', 'l2'],  # regularization type\n",
    "    'solver': ['liblinear', 'saga' ]}  # optimization algorithm\n",
    "\n",
    "# perform cross-validation with GridSearchCV\n",
    "grid = GridSearchCV(logreg, param_grid_r, cv=5, scoring='recall')\n",
    "\n",
    "# fit the GridSearchCV object to the training data\n",
    "grid.fit(X_train_encoded, y_train)\n",
    "\n",
    "# print the best hyperparameters found\n",
    "print(\"Best hyperparameters: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "255db1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-24 {color: black;background-color: white;}#sk-container-id-24 pre{padding: 0;}#sk-container-id-24 div.sk-toggleable {background-color: white;}#sk-container-id-24 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-24 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-24 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-24 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-24 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-24 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-24 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-24 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-24 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-24 div.sk-item {position: relative;z-index: 1;}#sk-container-id-24 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-24 div.sk-item::before, #sk-container-id-24 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-24 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-24 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-24 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-24 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-24 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-24 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-24 div.sk-label-container {text-align: center;}#sk-container-id-24 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-24 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-24\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" checked><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, solver='liblinear')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit logistic regression using the Best hyperparameters\n",
    "logreg2 = LogisticRegression(C = 1, penalty = 'l2', solver = 'liblinear')\n",
    "logreg2.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4a6c26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caculate the predicted values\n",
    "svm_pred = svm2.predict(X_test_encoded)\n",
    "logreg_pred = logreg2.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e41db4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, \\\n",
    "accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Confusion matrix\n",
    "svm_cm = confusion_matrix(y_test, svm_pred)\n",
    "logreg_cm = confusion_matrix(y_test, logreg_pred)\n",
    "\n",
    "# Accuracy\n",
    "svm_acc = accuracy_score(y_test, svm_pred)\n",
    "logreg_acc = accuracy_score(y_test, logreg_pred)\n",
    "\n",
    "# Precision\n",
    "svm_precision = precision_score(y_test, svm_pred)\n",
    "logreg_precision = precision_score(y_test, logreg_pred)\n",
    "\n",
    "# Recall\n",
    "svm_recall = recall_score(y_test, svm_pred)\n",
    "logreg_recall = recall_score(y_test, logreg_pred)\n",
    "\n",
    "# F1-score\n",
    "svm_f1 = f1_score(y_test, svm_pred)\n",
    "logreg_f1 = f1_score(y_test, logreg_pred)\n",
    "\n",
    "# AUC\n",
    "svm_auc = roc_auc_score(y_test, svm_pred)\n",
    "logreg_auc = roc_auc_score(y_test, logreg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "94a3bce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM results:\n",
      "Confusion matrix:\n",
      "[[2797 1611]\n",
      " [1748 1033]]\n",
      "Accuracy: 0.5327583808596467\n",
      "Precision: 0.39069591527987896\n",
      "Recall: 0.37144911902193456\n",
      "F1-score: 0.38082949308755765\n",
      "AUC: 0.5029886248467206\n",
      "Logistic regression results:\n",
      "Confusion matrix:\n",
      "[[4198  210]\n",
      " [2589  192]]\n",
      "Accuracy: 0.610655167617193\n",
      "Precision: 0.47761194029850745\n",
      "Recall: 0.06903991370010787\n",
      "F1-score: 0.12064090480678603\n",
      "AUC: 0.510699630171288\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM results:\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(svm_cm)\n",
    "print(\"Accuracy:\", svm_acc)\n",
    "print(\"Precision:\", svm_precision)\n",
    "print(\"Recall:\", svm_recall)\n",
    "print(\"F1-score:\", svm_f1)\n",
    "print(\"AUC:\", svm_auc)\n",
    "\n",
    "print(\"Logistic regression results:\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(logreg_cm)\n",
    "print(\"Accuracy:\", logreg_acc)\n",
    "print(\"Precision:\", logreg_precision)\n",
    "print(\"Recall:\", logreg_recall)\n",
    "print(\"F1-score:\", logreg_f1)\n",
    "print(\"AUC:\", logreg_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5600eaa",
   "metadata": {},
   "source": [
    "## question 1\n",
    "\n",
    "For the SVM model, I used C = 1, gamma = 1, kernel = 'sigmoid' as the hyperparameters. They represent that the SVM model is using a sigmoid kernel with a gamma coefficient of 1. C is a tuning parameter, which controles \"the hardness of the margin\". Specifacally, for very large C, the margin is hard, and points cannot lie in it. For smaller C, the margin is softer, and can grow to encompass some points. Since most common values for C are in the range of 0.1 to 100, C=1 is not considered a large value. gamma is a hyperparameter that determines the kernel coefficient for non-linear SVM models. It defines how far the influence of a single training example reaches, with low values meaning 'far' and high values meaning 'close'. When gamma is low, the decision boundary is smoother, while for high gamma values, the decision boundary is more complex and more prone to overfitting. \n",
    "\n",
    "For the logistic regression, I used C = 1, penalty = 'l2', solver = 'liblinear' as the hyperparameters. They represent that the logistic regression model is using 'l2' as the regularization type with a regularization parameter of C=1. C controls the inverse of regularization strength (smaller values specify stronger regularization). 'l2' regularization results in solutions with all coefficients being non-zero. 'l2' regularization is less sensitive to outliers and is less prone to overfitting than 'l1' regularization. solver is the algorithm used for optimization during the training of the model. solver='liblinear' means that we are using the Liblinear optimizer, which uses coordinate descent algorithm.\n",
    "\n",
    "All these hyperparameters are got using cross-validation. I tried different settings and compared them to get these final hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81afa10",
   "metadata": {},
   "source": [
    "## question 2\n",
    "\n",
    "The confusion matrix retult from svm model is [[2797 1611][1748 1033]].2797 is the counts for True negatives (TN), which represents the number of predictions that the model correctly predicted the \"not injured\" class. 1611 is the counts for False positives (FP), which represents the number of predictions that the model predicted \"injured\" but the actual class was \"not injured\". 1748 is False negatives (FN),  which represents the number of predictions that the model predicted the \"not injured\" but the actual class was \"injured\". 1033 is the counts for True positives (TP), which represents the number of predictions that the model correctly predicted the \"injured\".\n",
    "\n",
    "The confusion matrix retult from logistic regression model is [[4198  210][2589  192]]. 4198 is the counts for True negatives (TN), which represents the number of predictions that the model correctly predicted the \"not injured\" class. 210 is the counts for False positives (FP), which represents the number of predictions that the model predicted \"injured\" but the actual class was \"not injured\". 2589 is False negatives (FN),  which represents the number of predictions that the model predicted the \"not injured\" but the actual class was \"injured\". 192 is the counts for True positives (TP), which represents the number of predictions that the model correctly predicted the \"injured\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9d5b7b",
   "metadata": {},
   "source": [
    "## question 3\n",
    "\n",
    "Comparing the SVM and logistic regression results, we can see that the logistic regression model has higher accuracy (0.611 vs. 0.533) and precision (0.478 vs. 0.391), but lower recall (0.069 vs. 0.371) and F1-score (0.121 vs. 0.381). It means that firstly, logistic regression model has higher percentage of correct predictions over all predictions. Second, logistic regression model also has higher percentage of true positives (correctly predicted positive instances) among all predicted positives. Third, SVM has higher percentage of true positives among all actual positive instances. Fourth, SVM has a better balance for precision and recall. In addition, both models have similar AUC scores (both about 0.5, and logistic regression is silightly higher), which suggest that they perform similarly in terms of ranking the predicted probabilities. Unfortuately, 0.5 is equivalent to random guessing and suggests that the model is not useful for predicting the target variable.\n",
    "\n",
    "Overall, the choice of which model to use would depend on the specific goals and constraints of the problem. If precision is more important (e.g., false positives are more costly than false negatives), then the logistic regression model may be preferred. If recall is more important (e.g., false negatives are more costly than false positives), then the SVM model may be preferred."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
